"""
ç¬¬äºŒé˜¶æ®µ - XPathç½‘é¡µè§£æ

XPathæ˜¯ä¸€ç§åœ¨XML/HTMLæ–‡æ¡£ä¸­æŸ¥æ‰¾ä¿¡æ¯çš„è¯­è¨€ï¼ŒåŠŸèƒ½å¼ºå¤§
"""

from lxml import etree
import requests

# ==================== 1. XPathåŸºç¡€è¯­æ³• ====================

def xpath_basics():
    """
    XPathåŸºç¡€è¯­æ³•è®²è§£
    """
    print("=" * 60)
    print("1. XPathåŸºç¡€è¯­æ³•")
    print("=" * 60)
    
    print("""
XPathï¼ˆXML Path Languageï¼‰æ˜¯æŸ¥æ‰¾XML/HTMLèŠ‚ç‚¹çš„è¯­è¨€

ã€åŸºæœ¬è¯­æ³•ã€‘
/     ä»æ ¹èŠ‚ç‚¹é€‰æ‹©
//    é€‰æ‹©æ‰€æœ‰åŒ¹é…çš„èŠ‚ç‚¹ï¼ˆä¸è€ƒè™‘ä½ç½®ï¼‰
.     å½“å‰èŠ‚ç‚¹
..    çˆ¶èŠ‚ç‚¹
@     é€‰æ‹©å±æ€§

ã€å¸¸ç”¨è¡¨è¾¾å¼ã€‘
/html/body/div          ä»æ ¹å¼€å§‹çš„ç»å¯¹è·¯å¾„
//div                   æ‰€æœ‰divå…ƒç´ 
//div[@class='news']    classä¸ºnewsçš„div
//div[@id]              æœ‰idå±æ€§çš„div
//a/@href               æ‰€æœ‰aæ ‡ç­¾çš„hrefå±æ€§
//div[1]                ç¬¬ä¸€ä¸ªdivï¼ˆç´¢å¼•ä»1å¼€å§‹ï¼ï¼‰
//div[last()]           æœ€åä¸€ä¸ªdiv
//div[position()<3]     å‰ä¸¤ä¸ªdiv

ã€è°“è¯ï¼ˆæ¡ä»¶ï¼‰ã€‘
//div[@class='news']    å±æ€§ç­‰äº
//div[contains(@class,'news')]  å±æ€§åŒ…å«
//div[starts-with(@class,'news')]  å±æ€§å¼€å¤´
//p[text()='Python']    æ–‡æœ¬å†…å®¹ç­‰äº
//div[count(p)>2]       åŒ…å«è¶…è¿‡2ä¸ªpæ ‡ç­¾

ã€è¿ç®—ç¬¦ã€‘
|     æˆ–ï¼ˆé€‰æ‹©å¤šä¸ªè·¯å¾„ï¼‰
and   ä¸
or    æˆ–

ã€ç¤ºä¾‹ã€‘
//div[@class='news']//a/@href     é€‰æ‹©classä¸ºnewsçš„divä¸‹æ‰€æœ‰aæ ‡ç­¾çš„href
//div[@class='news' or @class='hot']  é€‰æ‹©classä¸ºnewsæˆ–hotçš„div
//p[@class='content' and @id='main']  åŒæ—¶æ»¡è¶³ä¸¤ä¸ªæ¡ä»¶
    """)


# ==================== 2. XPathåŸºæœ¬ä½¿ç”¨ ====================

def xpath_basic_usage():
    """
    XPathåŸºæœ¬ä½¿ç”¨ç¤ºä¾‹
    """
    print("=" * 60)
    print("2. XPathåŸºæœ¬ä½¿ç”¨")
    print("=" * 60)
    
    html = """
    <html>
        <body>
            <div class="container">
                <h1 id="title">æ–°é—»åˆ—è¡¨</h1>
                <div class="news">
                    <a href="/news/1">æ–°é—»æ ‡é¢˜1</a>
                    <span class="date">2024-01-01</span>
                </div>
                <div class="news">
                    <a href="/news/2">æ–°é—»æ ‡é¢˜2</a>
                    <span class="date">2024-01-02</span>
                </div>
                <div class="hot">
                    <a href="/news/3">çƒ­é—¨æ–°é—»</a>
                </div>
            </div>
        </body>
    </html>
    """
    
    # åˆ›å»ºHTMLæ ‘
    tree = etree.HTML(html)
    
    # 1. é€‰æ‹©æ‰€æœ‰divæ ‡ç­¾
    divs = tree.xpath('//div')
    print(f"âœ… æ‰€æœ‰div: {len(divs)}ä¸ª")
    
    # 2. é€‰æ‹©classä¸ºnewsçš„div
    news_divs = tree.xpath('//div[@class="news"]')
    print(f"âœ… classä¸ºnewsçš„div: {len(news_divs)}ä¸ª")
    
    # 3. è·å–h1æ ‡ç­¾çš„æ–‡æœ¬
    title = tree.xpath('//h1[@id="title"]/text()')
    print(f"âœ… æ ‡é¢˜: {title[0] if title else None}")
    
    # 4. è·å–æ‰€æœ‰aæ ‡ç­¾çš„hrefå±æ€§
    hrefs = tree.xpath('//a/@href')
    print(f"âœ… æ‰€æœ‰é“¾æ¥: {hrefs}")
    
    # 5. è·å–æ‰€æœ‰aæ ‡ç­¾çš„æ–‡æœ¬
    link_texts = tree.xpath('//a/text()')
    print(f"âœ… æ‰€æœ‰é“¾æ¥æ–‡æœ¬: {link_texts}")
    
    # 6. é€‰æ‹©ç¬¬ä¸€ä¸ªnews div
    first_news = tree.xpath('//div[@class="news"][1]')
    print(f"âœ… ç¬¬ä¸€ä¸ªnews divå­˜åœ¨: {len(first_news) > 0}")
    
    # 7. è·å–ç¬¬ä¸€ä¸ªnews divä¸‹çš„aæ ‡ç­¾æ–‡æœ¬
    first_news_title = tree.xpath('//div[@class="news"][1]//a/text()')
    print(f"âœ… ç¬¬ä¸€æ¡æ–°é—»: {first_news_title[0] if first_news_title else None}")
    
    print()


# ==================== 3. XPathé«˜çº§ç”¨æ³• ====================

def xpath_advanced():
    """
    XPathé«˜çº§ç”¨æ³•
    """
    print("=" * 60)
    print("3. XPathé«˜çº§ç”¨æ³•")
    print("=" * 60)
    
    html = """
    <div class="product-list">
        <div class="product hot-sale">
            <h3 class="product-title">iPhone 15 Pro</h3>
            <span class="price" data-value="7999">Â¥7999</span>
            <span class="rating">4.8</span>
        </div>
        <div class="product">
            <h3 class="product-title">MacBook Pro</h3>
            <span class="price" data-value="12999">Â¥12999</span>
            <span class="rating">4.9</span>
        </div>
        <div class="product new-arrival">
            <h3 class="product-title">iPad Air</h3>
            <span class="price" data-value="4999">Â¥4999</span>
            <span class="rating">4.7</span>
        </div>
    </div>
    """
    
    tree = etree.HTML(html)
    
    # 1. contains() - å±æ€§åŒ…å«æŸä¸ªå€¼
    hot_products = tree.xpath('//div[contains(@class, "hot")]')
    print(f"âœ… çƒ­é”€å•†å“(contains): {len(hot_products)}ä¸ª")
    
    # 2. starts-with() - å±æ€§ä»¥æŸä¸ªå€¼å¼€å¤´
    product_titles = tree.xpath('//h3[starts-with(@class, "product")]')
    print(f"âœ… å•†å“æ ‡é¢˜(starts-with): {len(product_titles)}ä¸ª")
    
    # 3. text() - é€‰æ‹©æ–‡æœ¬èŠ‚ç‚¹
    all_text = tree.xpath('//h3/text()')
    print(f"âœ… æ‰€æœ‰æ ‡é¢˜: {all_text}")
    
    # 4. è·å–data-*å±æ€§
    prices = tree.xpath('//span[@class="price"]/@data-value')
    print(f"âœ… æ‰€æœ‰ä»·æ ¼: {prices}")
    
    # 5. æ¡ä»¶ç­›é€‰ - ä»·æ ¼å¤§äº5000
    # XPathä¸æ”¯æŒç›´æ¥çš„æ•°å€¼æ¯”è¾ƒï¼Œéœ€è¦å…ˆè·å–æ‰€æœ‰å…ƒç´ å†åœ¨Pythonä¸­å¤„ç†
    expensive_products = tree.xpath('//span[@data-value]')
    print(f"âœ… æœ‰ä»·æ ¼çš„å•†å“: {len(expensive_products)}ä¸ª")
    
    # 6. å¤šä¸ªæ¡ä»¶ï¼ˆandï¼‰
    hot_new = tree.xpath('//div[contains(@class, "hot") or contains(@class, "new")]')
    print(f"âœ… çƒ­é”€æˆ–æ–°å“: {len(hot_new)}ä¸ª")
    
    # 7. çˆ¶èŠ‚ç‚¹é€‰æ‹©ï¼ˆ..ï¼‰
    # æ‰¾åˆ°è¯„åˆ†4.9çš„å•†å“çš„æ ‡é¢˜
    title = tree.xpath('//span[@class="rating" and text()="4.9"]/../h3/text()')
    print(f"âœ… è¯„åˆ†4.9çš„å•†å“: {title}")
    
    # 8. å…„å¼ŸèŠ‚ç‚¹é€‰æ‹©ï¼ˆfollowing-sibling::ï¼‰
    # æ‰¾åˆ°æ ‡é¢˜åé¢çš„ä»·æ ¼
    price_after_title = tree.xpath('//h3[@class="product-title"][1]/following-sibling::span[@class="price"]/text()')
    print(f"âœ… ç¬¬ä¸€ä¸ªå•†å“ä»·æ ¼: {price_after_title}")
    
    # 9. è½´ï¼ˆaxisï¼‰- æ›´å¤æ‚çš„å…³ç³»
    # ancestor:: ç¥–å…ˆèŠ‚ç‚¹
    # descendant:: åä»£èŠ‚ç‚¹
    # following:: å½“å‰èŠ‚ç‚¹ä¹‹åçš„æ‰€æœ‰èŠ‚ç‚¹
    # preceding:: å½“å‰èŠ‚ç‚¹ä¹‹å‰çš„æ‰€æœ‰èŠ‚ç‚¹
    
    print()


# ==================== 4. XPath vs CSSé€‰æ‹©å™¨å¯¹æ¯” ====================

def xpath_vs_css():
    """
    XPathå’ŒCSSé€‰æ‹©å™¨å¯¹æ¯”
    """
    print("=" * 60)
    print("4. XPath vs CSSé€‰æ‹©å™¨å¯¹æ¯”")
    print("=" * 60)
    
    print("""
ã€åŠŸèƒ½å¯¹æ¯”ã€‘

éœ€æ±‚                    CSSé€‰æ‹©å™¨               XPath
-----------------------------------------------------------
é€‰æ‹©æ‰€æœ‰div            div                     //div
é€‰æ‹©classä¸ºnewsçš„div   .news                   //div[@class='news']
é€‰æ‹©idä¸ºmainçš„div      #main                   //div[@id='main']
é€‰æ‹©ç¬¬ä¸€ä¸ªdiv          div:first-child         //div[1]
é€‰æ‹©æœ€åä¸€ä¸ªdiv        div:last-child          //div[last()]
é€‰æ‹©ç¬¬nä¸ªdiv           div:nth-child(n)        //div[n]
é€‰æ‹©æœ‰hrefå±æ€§çš„a      a[href]                 //a[@href]
é€‰æ‹©æ–‡æœ¬å†…å®¹           (ä¸æ”¯æŒ)                //div[text()='xxx']
é€‰æ‹©çˆ¶èŠ‚ç‚¹             (ä¸æ”¯æŒ)                //div/..
è·å–å±æ€§å€¼             (éœ€è¦é¢å¤–å¤„ç†)          //a/@href
åŒ…å«æŸä¸ªç±»             [class*='news']         //div[contains(@class,'news')]

ã€æ€»ç»“ã€‘
- CSSé€‰æ‹©å™¨ï¼šç®€æ´ï¼Œé€‚åˆç®€å•åœºæ™¯
- XPathï¼šåŠŸèƒ½æ›´å¼ºå¤§ï¼Œå¯ä»¥å‘ä¸ŠæŸ¥æ‰¾çˆ¶èŠ‚ç‚¹ï¼Œæ”¯æŒæ›´å¤æ‚çš„é€»è¾‘

ã€å»ºè®®ã€‘
- ç®€å•æŸ¥æ‰¾ï¼šç”¨CSSé€‰æ‹©å™¨ï¼ˆBeautifulSoupï¼‰
- å¤æ‚é€»è¾‘ï¼šç”¨XPathï¼ˆlxmlï¼‰
- æ–‡æœ¬åŒ¹é…ï¼šç”¨XPath
- éœ€è¦çˆ¶èŠ‚ç‚¹ï¼šç”¨XPath
    """)


# ==================== 5. å®æˆ˜ï¼šè§£æå•†å“åˆ—è¡¨ ====================

def parse_products():
    """
    å®æˆ˜ï¼šä½¿ç”¨XPathè§£æå•†å“åˆ—è¡¨
    """
    print("=" * 60)
    print("5. å®æˆ˜ï¼šè§£æå•†å“åˆ—è¡¨")
    print("=" * 60)
    
    html = """
    <div class="shop-list">
        <div class="item" data-id="1">
            <img src="/img/product1.jpg" alt="å•†å“1"/>
            <h3 class="title">Pythonç¼–ç¨‹å…¥é—¨</h3>
            <div class="info">
                <span class="price">Â¥89.00</span>
                <span class="sales">å·²å”®1000+</span>
            </div>
            <div class="rating">
                <span class="score">4.8</span>
                <span class="comments">200æ¡è¯„è®º</span>
            </div>
        </div>
        <div class="item" data-id="2">
            <img src="/img/product2.jpg" alt="å•†å“2"/>
            <h3 class="title">Javaæ ¸å¿ƒæŠ€æœ¯</h3>
            <div class="info">
                <span class="price">Â¥128.00</span>
                <span class="sales">å·²å”®800+</span>
            </div>
            <div class="rating">
                <span class="score">4.9</span>
                <span class="comments">150æ¡è¯„è®º</span>
            </div>
        </div>
        <div class="item" data-id="3">
            <img src="/img/product3.jpg" alt="å•†å“3"/>
            <h3 class="title">ç®—æ³•å¯¼è®º</h3>
            <div class="info">
                <span class="price">Â¥158.00</span>
                <span class="sales">å·²å”®500+</span>
            </div>
            <div class="rating">
                <span class="score">5.0</span>
                <span class="comments">80æ¡è¯„è®º</span>
            </div>
        </div>
    </div>
    """
    
    tree = etree.HTML(html)
    
    # è·å–æ‰€æœ‰å•†å“
    items = tree.xpath('//div[@class="item"]')
    print(f"âœ… å…±æ‰¾åˆ° {len(items)} ä¸ªå•†å“\n")
    
    products = []
    for item in items:
        # æå–å„å­—æ®µï¼ˆä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œä»itemå¼€å§‹ï¼‰
        product_id = item.xpath('./@data-id')[0]
        title = item.xpath('.//h3[@class="title"]/text()')[0]
        price = item.xpath('.//span[@class="price"]/text()')[0]
        sales = item.xpath('.//span[@class="sales"]/text()')[0]
        score = item.xpath('.//span[@class="score"]/text()')[0]
        comments = item.xpath('.//span[@class="comments"]/text()')[0]
        img_url = item.xpath('.//img/@src')[0]
        
        product = {
            'id': product_id,
            'title': title.strip(),
            'price': price,
            'sales': sales,
            'score': float(score),
            'comments': comments,
            'image': img_url
        }
        
        products.append(product)
    
    # æ‰“å°ç»“æœ
    for i, p in enumerate(products, 1):
        print(f"å•†å“ {i}:")
        print(f"  ID: {p['id']}")
        print(f"  æ ‡é¢˜: {p['title']}")
        print(f"  ä»·æ ¼: {p['price']}")
        print(f"  é”€é‡: {p['sales']}")
        print(f"  è¯„åˆ†: {p['score']}")
        print(f"  è¯„è®º: {p['comments']}")
        print(f"  å›¾ç‰‡: {p['image']}")
        print()


# ==================== 6. å®æˆ˜ï¼šçˆ¬å–çœŸå®ç½‘ç«™ ====================

def crawl_with_xpath():
    """
    ä½¿ç”¨XPathçˆ¬å–çœŸå®ç½‘ç«™
    """
    print("=" * 60)
    print("6. ä½¿ç”¨XPathçˆ¬å–çœŸå®ç½‘ç«™")
    print("=" * 60)
    
    try:
        url = "http://books.toscrape.com/"
        
        headers = {
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
        }
        
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        # ä½¿ç”¨lxmlè§£æ
        tree = etree.HTML(response.text)
        
        # æå–ä¹¦ç±ä¿¡æ¯
        books = tree.xpath('//article[@class="product_pod"]')
        print(f"âœ… æ‰¾åˆ° {len(books)} æœ¬ä¹¦\n")
        
        for i, book in enumerate(books[:5], 1):
            # æ ‡é¢˜ï¼ˆæ³¨æ„ï¼štitleå±æ€§åœ¨aæ ‡ç­¾ä¸Šï¼‰
            title = book.xpath('.//h3/a/@title')[0]
            
            # ä»·æ ¼
            price = book.xpath('.//p[@class="price_color"]/text()')[0]
            
            # è¯„åˆ†ï¼ˆåœ¨classå±æ€§ä¸­ï¼‰
            rating_class = book.xpath('.//p[contains(@class, "star-rating")]/@class')[0]
            rating = rating_class.split()[-1]  # æå–è¯„åˆ†ç­‰çº§
            
            # é“¾æ¥
            link = book.xpath('.//h3/a/@href')[0]
            
            # åº“å­˜çŠ¶æ€
            availability = book.xpath('.//p[@class="instock availability"]/text()')[1].strip()
            
            print(f"ä¹¦ç± {i}:")
            print(f"  æ ‡é¢˜: {title}")
            print(f"  ä»·æ ¼: {price}")
            print(f"  è¯„åˆ†: {rating}")
            print(f"  é“¾æ¥: {link}")
            print(f"  åº“å­˜: {availability}")
            print()
        
        print("âœ… çˆ¬å–æˆåŠŸï¼")
        
    except Exception as e:
        print(f"âŒ çˆ¬å–å¤±è´¥: {e}")


# ==================== 7. XPathè°ƒè¯•æŠ€å·§ ====================

def xpath_debugging():
    """
    XPathè°ƒè¯•æŠ€å·§
    """
    print("=" * 60)
    print("7. XPathè°ƒè¯•æŠ€å·§")
    print("=" * 60)
    
    print("""
ã€è°ƒè¯•æŠ€å·§ã€‘

1. æµè§ˆå™¨æ§åˆ¶å°æµ‹è¯•
   - æ‰“å¼€Chromeå¼€å‘è€…å·¥å…·ï¼ˆF12ï¼‰
   - åˆ‡æ¢åˆ°Consoleæ ‡ç­¾
   - ä½¿ç”¨ $x() å‡½æ•°æµ‹è¯•XPath
   
   ä¾‹å¦‚ï¼š
   $x('//div[@class="news"]')           // é€‰æ‹©å…ƒç´ 
   $x('//div[@class="news"]/text()')    // é€‰æ‹©æ–‡æœ¬
   $x('//a/@href')                      // é€‰æ‹©å±æ€§

2. å¸¸è§é—®é¢˜æ’æŸ¥

é—®é¢˜1ï¼šè¿”å›ç©ºåˆ—è¡¨
- æ£€æŸ¥HTMLæ˜¯å¦åŠ è½½å®Œæ•´ï¼ˆå¯èƒ½æ˜¯JavaScriptæ¸²æŸ“ï¼‰
- æ£€æŸ¥XPathè¡¨è¾¾å¼æ˜¯å¦æ­£ç¡®
- æ£€æŸ¥å¤§å°å†™ï¼ˆHTMLæ ‡ç­¾ä¸åŒºåˆ†ï¼Œå±æ€§å€¼åŒºåˆ†ï¼‰

é—®é¢˜2ï¼šè·å–ä¸åˆ°æ–‡æœ¬
- ä½¿ç”¨ /text() è·å–ç›´æ¥æ–‡æœ¬
- ä½¿ç”¨ //text() è·å–æ‰€æœ‰åä»£æ–‡æœ¬
- ä½¿ç”¨ string() å‡½æ•°è·å–æ‰€æœ‰æ–‡æœ¬ï¼ˆXPath 1.0ï¼‰

é—®é¢˜3ï¼šç´¢å¼•é”™è¯¯
- XPathç´¢å¼•ä»1å¼€å§‹ï¼ˆä¸æ˜¯0ï¼ï¼‰
- [1] è¡¨ç¤ºç¬¬ä¸€ä¸ªï¼Œä¸æ˜¯ [0]

3. å®ç”¨å·¥å…·
   - Chrome XPath Helper æ’ä»¶
   - åœ¨çº¿XPathæµ‹è¯•å·¥å…·
   - lxmlçš„tostring()æŸ¥çœ‹è§£æåçš„HTML

4. ä¼˜åŒ–å»ºè®®
   - å°½é‡ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼ˆ.//)è€Œä¸æ˜¯ç»å¯¹è·¯å¾„
   - é¿å…ä½¿ç”¨å¤ªé•¿çš„XPath
   - ä½¿ç”¨contains()æé«˜å®¹é”™æ€§
   - å…ˆè·å–çˆ¶å…ƒç´ ï¼Œå†åœ¨å…¶å†…éƒ¨æŸ¥æ‰¾å­å…ƒç´ 
    """)
    
    # å®é™…è°ƒè¯•ç¤ºä¾‹
    html = """
    <div class="container">
        <p>æ®µè½1</p>
        <div class="inner">
            <p>æ®µè½2</p>
        </div>
    </div>
    """
    
    tree = etree.HTML(html)
    
    print("\nã€ç¤ºä¾‹ã€‘")
    
    # è·å–ç›´æ¥æ–‡æœ¬ vs æ‰€æœ‰æ–‡æœ¬
    direct_text = tree.xpath('//div[@class="container"]/text()')
    all_text = tree.xpath('//div[@class="container"]//text()')
    
    print(f"ç›´æ¥æ–‡æœ¬ /text(): {[t.strip() for t in direct_text if t.strip()]}")
    print(f"æ‰€æœ‰æ–‡æœ¬ //text(): {[t.strip() for t in all_text if t.strip()]}")
    
    print()


# ==================== ç»ƒä¹ é¢˜ ====================

def exercises():
    """
    è¯¾åç»ƒä¹ é¢˜
    """
    print("=" * 60)
    print("ğŸ“ è¯¾åç»ƒä¹ ")
    print("=" * 60)
    
    print("""
è¯·å®Œæˆä»¥ä¸‹ç»ƒä¹ ï¼š

ã€ç»ƒä¹ 1ã€‘åŸºç¡€XPath
ç»™å®šHTMLï¼Œä½¿ç”¨XPathæå–ï¼š
- æ‰€æœ‰h2æ ‡ç­¾çš„æ–‡æœ¬
- æ‰€æœ‰classåŒ…å«'highlight'çš„å…ƒç´ 
- ç¬¬2ä¸ªå’Œç¬¬3ä¸ªliå…ƒç´ 
- æ‰€æœ‰imgæ ‡ç­¾çš„srcå±æ€§

ã€ç»ƒä¹ 2ã€‘å¤æ‚ç­›é€‰
ä½¿ç”¨XPathé€‰æ‹©ï¼š
- ä»·æ ¼å¤§äº100çš„å•†å“ï¼ˆéœ€è¦ç»“åˆPythonå¤„ç†ï¼‰
- è¯„åˆ†ç­‰äº5æ˜Ÿçš„å•†å“
- æ ‡é¢˜åŒ…å«"Python"çš„æ–‡ç« 
- åŒæ—¶æœ‰classå’Œidå±æ€§çš„div

ã€ç»ƒä¹ 3ã€‘å…³ç³»å¯¼èˆª
ä½¿ç”¨XPathï¼š
- æ‰¾åˆ°æŸä¸ªå…ƒç´ çš„çˆ¶èŠ‚ç‚¹
- æ‰¾åˆ°æŸä¸ªå…ƒç´ çš„ä¸‹ä¸€ä¸ªå…„å¼ŸèŠ‚ç‚¹
- æ‰¾åˆ°æŸä¸ªå…ƒç´ çš„æ‰€æœ‰ç¥–å…ˆèŠ‚ç‚¹
- æ‰¾åˆ°è¯„åˆ†æœ€é«˜çš„å•†å“çš„æ ‡é¢˜

ã€ç»ƒä¹ 4ã€‘å®æˆ˜é¡¹ç›®
çˆ¬å– http://books.toscrape.com/
- çˆ¬å–æ‰€æœ‰åˆ†ç±»é“¾æ¥
- è¿›å…¥æ¯ä¸ªåˆ†ç±»çˆ¬å–ä¹¦ç±
- æå–ï¼šæ ‡é¢˜ã€ä»·æ ¼ã€è¯„åˆ†ã€åº“å­˜
- ä¿å­˜ä¸ºJSONæ–‡ä»¶

æç¤ºï¼š
- å…ˆåœ¨æµè§ˆå™¨Consoleç”¨$x()æµ‹è¯•è¡¨è¾¾å¼
- ä½¿ç”¨Chromeå¼€å‘è€…å·¥å…·æŸ¥çœ‹å…ƒç´ ç»“æ„
- æ³¨æ„ç´¢å¼•ä»1å¼€å§‹ï¼
    """)


# ==================== ä¸»å‡½æ•° ====================

def main():
    """
    ä¸»å‡½æ•°
    """
    print("\n" + "=" * 60)
    print("XPathç½‘é¡µè§£ææ•™ç¨‹")
    print("=" * 60 + "\n")
    
    xpath_basics()
    xpath_basic_usage()
    xpath_advanced()
    xpath_vs_css()
    parse_products()
    crawl_with_xpath()
    xpath_debugging()
    exercises()
    
    print("=" * 60)
    print("âœ… XPathå­¦ä¹ å®Œæˆï¼")
    print("ğŸ’¡ æ ¸å¿ƒè¦ç‚¹ï¼š")
    print("   1. // é€‰æ‹©æ‰€æœ‰åŒ¹é…èŠ‚ç‚¹")
    print("   2. [@attr='value'] å±æ€§ç­›é€‰")
    print("   3. /text() è·å–æ–‡æœ¬ï¼Œ/@attr è·å–å±æ€§")
    print("   4. contains() æ¨¡ç³ŠåŒ¹é…")
    print("   5. XPathç´¢å¼•ä»1å¼€å§‹ï¼")
    print("â­ï¸  ä¸‹ä¸€æ­¥ï¼šå­¦ä¹  03_regex.py")
    print("=" * 60)


if __name__ == "__main__":
    main()

